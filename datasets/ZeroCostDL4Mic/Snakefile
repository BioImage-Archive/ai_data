import json
import os
import pandas as pd
import pathlib

# Read the input JSON file
with open("metadata.json") as f:
    metadata = json.load(f)

# import logging
# logger = logging.getLogger(__name__)

projects_metadata = list(metadata.keys())
projects_metadata.remove("CycleGAN SDCM to SRRF_v1")
projects_metadata.remove("DeepSTORM dataset_v1")
# projects_metadata = ["YoloV2 dataset_v1"]
meta_project_name = "ZeroCostDL4Mic"
# print(projects_metadata)
metadata_files = ["metadata.tsv","file_list.tsv","annotations_list.tsv"]
rule all:
    input:
        "metadata.json",
        expand("{meta_project}/{project}/{metadata_files}",meta_project=meta_project_name,
        project=projects_metadata,
        metadata_files=metadata_files,
        ),
        
 
checkpoint download_and_extract:
    input:
        metadata_json="metadata.json",
    output:
        folder=directory("data/{project,[^/]+}"),
        archive="{project,[^/]+}.zip",
    params:
        url=lambda wildcards, input: metadata[wildcards.project]["url"],
    shell:
        """
        wget "{params.url}" -O "{output.archive}"
        mkdir -p "{output.folder}"
        unzip "{output.archive}" -d "{output.folder}"
        """

def get_jsons(wildcards):
    # breakpoint()
    checkpoint_output = checkpoints.download_and_extract.get(**wildcards).output
    # breakpoint()
    glob_string = f"data/{wildcards.project}/{{folder,.*}}/{{filename,[^/.][^/]*}}.{{ext,[^.]+}}" 
    folders, filenames, ext = glob_wildcards(glob_string)
    file_list = expand(
        f"{wildcards.meta_project}/{wildcards.project}/{{folder}}/{{filename}}.{{ext}}.metadata.json",
        zip,
        project=wildcards.project,
        folder=folders,
        filename=filenames,
        ext=ext,
        allow_missing=True,
    )

    # breakpoint()


    return file_list


rule save_file_list:
    output:
        json="{meta_project}/{project}/metadata_list.json",
    run:
        file_list = get_jsons(wildcards)
        if file_list == []:
            raise Exception("No files found")
        # breakpoint()
        with open(output.json, "w") as f:
            json.dump(file_list, f, indent=4)
        # shell(f"echo '{file_list}' > {output.json_file}")

def get_metadata(wildcards):
  file_list_json = f"{wildcards.meta_project}/{wildcards.project}/file_list.json"
  with open(file_list_json) as f:
    file_list = json.load(f)
  return file_list

def transform_row_to_dict(row):
    # Create a dictionary with the desired structure
    transformed_dict = {
        "path": row.name,  # Assuming the index of the DataFrame is the path
        "attributes": [],
        "type": "file"
    }
    
    # Add the column names and their corresponding values to the "attributes" list
    for column_name, column_value in row.items():
        attribute = {
            "name": column_name,
            "value": column_value
        }
        transformed_dict["attributes"].append(attribute)
    
    return transformed_dict

checkpoint collate_json:
    input:
        json=get_jsons,
    output:
        # json="{meta_project}/{project}/metadata.json",
        metadata_tsv="{meta_project}/{project}/metadata.tsv",
        file_list_tsv="{meta_project}/{project}/file_list.tsv",
        annotations_list_tsv="{meta_project}/{project}/annotations_list.tsv",
    run:
        # with open(input.json, 'r') as f:
        #   file_list = json.load(f)
        # Create an empty list to store individual DataFrames
        dfs = []
        # Iterate over the input JSON files
        for json_file in input.json:
            # Read JSON into a DataFrame
            df = pd.read_json(json_file, orient="index").T
            # Set the name of the index as the filepath
            # I think this needs to be smarter
            df["Files"] = json_file.replace('.metadata.json', '')
            # df['Files'] = df['Files'].str.replace('ZeroCostDL4Mic/', '')
            df.set_index("Files", inplace=True)

            # Append the DataFrame to the list
            dfs.append(df)

            # Concatenate all the DataFrames
        final_df = pd.concat(dfs)

        annotations_list_tsv = final_df[final_df["source image"]==""]
        file_list_tsv = final_df.drop(annotations_list_tsv.index)
        mapper = {
          output.metadata_tsv: final_df,
          output.file_list_tsv: file_list_tsv,
          output.annotations_list_tsv: annotations_list_tsv,
        }
        mapper.items()
        for file_name,df_to_save in mapper.items():
            df_to_save.to_csv(file_name, sep='\t')
        # breakpoint()
        # no_source_image = final_df.loc[final_df['source image'].isnull()]
        # breakpoint()
        # Save the list to a JSON file


rule copy_image:
  input:
    image="data/{project}/{folder}/{filename}.{ext}",
    # bkup="{meta_project}/{project}/{folder}/{filename}.{ext}.metadata.json",
  wildcard_constraints:
        meta_project="[^/]*",
        project="[^/]*",
        folder=".*",
        filename="[^/.]*",
        ext="[^.]*",
  output:
    image="{meta_project}/{project}/{folder}/{filename}.{ext}",
  shell:
    """
    ln "{input.image}" "{output.image}"
    """

# f"data/{wildcards.project}/{{folder,.*}}/{{filename,[^/.][^/]*}}.{{ext,[^.]+}}"

rule process_image:
    wildcard_constraints:
        meta_project="[^/]*",
        project="[^/]*",
        folder=".*",
        filename="[^/.]*",
        ext="[^.]*",
    input:
        cp="{meta_project}/{project}/{folder}/{filename}.{ext}",
        filename = "data/{project}/{folder}/{filename}.{ext}",
        # filename = "{meta_project}/{project}/{folder}/{filename}.{ext}"
    output:
        json="{meta_project}/{project}/{folder}/{filename}.{ext}.metadata.json"
    run:
        # path = pathlib.Path(input.json)
        # parent_dir = path.parent
        # full_path = f"{wildcards.meta_project}/{wildcards.project}/{wildcards.folder}/{wildcards.filename}.{wildcards.ext}"

        # Check if the metadata key exists
        metadata_key = metadata[wildcards.project].get("data", {}).get(wildcards.project+"/"+wildcards.folder, {})
        if not metadata_key:
            print(f"skip {wildcards.project}/{wildcards.folder}")
        else:
            # Check if 'source image' exists in metadata_key
            if 'source image' in metadata_key:
              if metadata_key["source image"] != "":
                source_image = f"{wildcards.meta_project}/{wildcards.project}/{metadata_key['source image']}/{wildcards.filename}.{wildcards.ext}"
                # breakpoint()
                metadata_key["source image"] = source_image

        metadata_dict = metadata_key

        with open(output.json, "w") as f:
            json.dump(metadata_dict, f, indent=4)